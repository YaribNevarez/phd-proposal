\section{State-of-the-art}

\subsection{Neural Network Resilience Analysis}

\subsubsection{Experimental Analysis}
The majority of the research on error resilience in neural networks have been experimental. They range from physical fault induction experiments in real hardware devices \cite{dos2018analyzing, whatmough2018dnn}, over fault injections in (virtual) hardware models \cite{azizimazreah2018tolerating, li2017understanding, salami2018resilience, dos2018analyzing}, to error simulations at the algorithmic behavior level \cite{marques2017unreliable, reagen2018ares, li2018smartshuttle}. Behavioral analysis can be connected to realistic hardware faults in a second step, by mapping the effect of these faults to error models in the algorithm domain \cite{piuri2001analysis}.

Experimental research found different determinants of neural network resilience, the most important being the number and type of errors, the data representation of the neural network, the DNN type, and the location where the error occurs. However, while experimental evaluation is useful for an accurate a posteriori resilience determination of a given DNN on hardware, it is cumbersome and provides only limited insight into a priori design choices for DNN developers to improve resilience at the algorithm level \cite{schorn2020automated}.

\subsubsection{Theoretical Analysis}
A theory-guided resilience analysis offers the advantage of being more directly interpretable and avoids lengthy fault injection experiments. El Mhamdi and Guerraoui \cite{guerraoui2017neurons} analytically derived easily computable bounds for the forward error propagation of neurons that are stuck-at-zero (crashed neurons) and for neurons that transmit arbitrary values (Byzantine neurons). They found that the choice of activation function and the number of neurons per layer are design choices that affect the forward error propagation. More precisely, an activation function with a low Lipschitz constant as well as a high number of neurons per layer can reduce forward error propagation.

A different analytical technique to derive neuron resilience prediction has been used in the context of approximate neural network computing. Backpropagation of error gradients, comparable to the technique used to determine weight updates during neural network training, has been used to estimate the average output sensitivity to perturbations in individual neurons \cite{venkataramani2014axnn, zhang2015approxann}.

Recently, Schorn et al. \cite{li2018smartshuttle} showed that a technique based on layerwise relevance propagation (LRP) \cite{bach2015pixel} outperforms gradient-based resilience prediction. Contrarily to gradient methods, which determine the sensitivity to small perturbations in neurons, LRP attributes to each neuron its absolute contribution to the DNN output \cite{montavon2018methods}, which can be interpreted as layerwise Taylor decomposition \cite{montavon2017explaining}. A high neuron relevance, averaged over a training set of input samples, corresponds to a high sensitivity against errors \cite{li2018smartshuttle}.

\subsection{Approximate Computing in Adders and Multipliers}
Driven by this high potential for power reduction, designing approximate circuits has attracted significant research interest. At the custom hardware level, approximate computing targets mainly arithmetic units \cite{miao2012modeling, shafique2015low, zervakis2019vader, saadat2018minimally} (e.g., adders and multipliers) since they form the core components of all computations and a vast number of error-tolerant applications. Specifically, in neural network inference the majority of the energy is consumed in the multiplication operations. Recent research showed that employing approximate multipliers in neural network inference can deliver significant energy savings for a minimal loss in accuracy \cite{saadat2018minimally, sarwar2018energy, tasoulas2020weight}. However, designing approximate circuits under quality constraints heavily increases the design time cycle since the designer has to verify both functionality and optimality as well as operating within error bounds \cite{zervakis2018multi}. This task becomes even more challenging as the circuit’s complexity increases. To this end, several research activities, such as approximate high-level synthesis (AHLS) \cite{lee2017high}, focus on automating the generation of approximate circuits. Approximate HLS estimates error propagation and distributes the available error budget to the different approximate sub-components of a larger accelerator, such as convolution operators and generic matrix multiply units. As a result, AHLS enables generating complex approximate micro-architectures that satisfy given quality requirements.

Moreover, approximate computing is further subdivided into static and dynamically reconfigurable approximation techniques \cite{zervakis2021approximate}. The latter, leveraging that error-tolerance and the induced errors are context- and input-dependent, aim to improve accuracy by providing a fine grain quality control and/or to further boost (power, energy, and/or run-time) gains by applying more aggressive approximation on less-sensitive inputs. Finally, reconfigurable approximation was also recently applied to address thermal constraints \cite{amrouch2020npu}. Instead of addressing thermal emergencies by reducing performance, by reducing the accuracy and hence dynamic power in the same area, the circuit’s power density decreases, resulting in lower temperatures.

\subsection{Approximate Artificial Neural Network}

With many approximate arithmetic building blocks presented in the literature (e.g., \cite{miao2012modeling, shafique2015low, zervakis2019vader, saadat2018minimally}), some recent works proposed to design approximate neural networks with approximate neuron designs. In \cite{du2014leveraging}, Du et al. first designed approximate neurons with approximate multipliers, and then search a subset of substitutions to choose the “best” configuration for the approximate neural networks design. However, this is a trial-and-error process instead of a systematic solution.

Recently, Venkataramani et al. \cite{venkataramani2014axnn} proposed a systematic approximate neural network design methodology, namely AxNN. In this work, the final error of the NN is first back propagated to get error apportions of each individual neuron. Neurons are then sorted based on the magnitude of their average error contribution, and classified as resilient or sensitive ones with a pre-determined threshold. Those resilient neurons are then designed as approximate ones for energy savings. Finally, retraining is performed to mitigate the impact of inexact hardware on the solution quality.